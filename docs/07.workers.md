# Workers

Ecewo provides powerful asynchronous capabilities for handling blocking operations efficiently, thanks to [libuv](https://libuv.org/). This guide covers how to execute CPU-bound tasks without blocking the event loop.

## Table of Contents

1. [Overview](#overview)
2. [The spawn() Function](#the-spawn-function)
3. [Fire-and-forget](#fire-and-forget)
4. [Wait and Respond](#wait-and-respond)
5. [Notes](#notes)

## Overview

Blocking computations should not run on the main event loop as they would block all other requests. Ecewo provides the `spawn()` function to handle blocking CPU-bound operations safely by executing them in libuv's thread pool.

## The spawn() Function

The `spawn()` function executes blocking work in a worker thread and runs a callback on the main thread when complete.

**Signature:**
```c
int spawn(void *context, spawn_handler_t work_fn, spawn_handler_t done_fn);
```

**Parameters:**
- `context`: User context pointer (must contain arena for memory allocation)
- `work_fn`: Function to execute in worker thread (safe to block here)
- `done_fn`: Callback when work completes (runs on main thread, can be NULL)

**Returns:**
- `0` on success
- `-1` on failure

**Callback Signature:**
```c
typedef void (*spawn_handler_t)(void *context);
```

## Fire-and-forget

Send a response to client immediately and run a background task. You can run multiple parallel tasks.

### Basic Usage

```c
#include "ecewo.h"

typedef struct
{
    int result;
} ComputeContext;

// This runs in a worker thread (safe to block)
void heavy_computation(void *context)
{
    ComputeContext *ctx = (ComputeContext *)context;

    // Simulate CPU-intensive work
    int sum = 0;

    for (int i = 0; i < 1000000000; i++)
    {
        sum += i;
    }
    
    ctx->result = sum;
    printf("Computation is done!\n");
    free(ctx);
}

// Route handler (runs on main thread)
void compute_handler(Req *req, Res *res)
{
    // Create context (arena-allocated)
    ComputeContext *ctx = malloc(sizeof(ComputeContext));

    ctx->result = 0;
    
    // Spawn the work
    spawn(ctx, heavy_computation, NULL);
    
    // Handler returns immediately
    // Computation will work on background
    send_text(res, OK, "The computation has been started!");
}

int main(void)
{
    server_init();
    
    get("/compute", compute_handler);
    
    server_listen(3000);
    server_run();
    
    return 0;
}
```

### Advanced Example

Here's a more complex example with multiple parallel tasks:

```c
#include "ecewo.h"

typedef struct
{
    int total;
    int completed;
    int results[3];
} ParallelContext;

static void parallel_work_1(void *context)
{
    ParallelContext *ctx = context;
    
    // Simulate CPU-intensive work
    // In real code: database query, file I/O, API call, etc.
    ctx->results[0] = 10;
}

static void parallel_work_2(void *context)
{
    ParallelContext *ctx = context;
    ctx->results[1] = 20;
}

static void parallel_work_3(void *context)
{
    ParallelContext *ctx = context;
    ctx->results[2] = 30;
}

static void parallel_done(void *context)
{
    ParallelContext *ctx = context;
    ctx->completed++;
    
    // All tasks completed
    if (ctx->completed == ctx->total)
    {
        int sum = ctx->results[0] + ctx->results[1] + ctx->results[2];
        printf("Background calculation completed. Sum: %d\n", sum);
        
        // Save to database, send to logging service, etc.
        
        // Cleanup
        free(ctx);
    }
}

void parallel_handler(Req *req, Res *res)
{
    // Send response immediately
    send_text(res, 200, "Calculation started in background");
    
    // Create context (malloc, not arena - will outlive the request)
    ParallelContext *ctx = malloc(sizeof(ParallelContext));
    ctx->total = 3;
    ctx->completed = 0;
    ctx->results[0] = 0;
    ctx->results[1] = 0;
    ctx->results[2] = 0;
    
    // Launch 3 parallel tasks
    spawn(ctx, parallel_work_1, parallel_done);
    spawn(ctx, parallel_work_2, parallel_done);
    spawn(ctx, parallel_work_3, parallel_done);
}
```

## Wait and Respond

Wait for the task and send a response to the client when it's done. You can run multiple parallel tasks.

### Basic Usage

```c
#include "ecewo.h"

typedef struct
{
    Res *res;
    int result;
} ComputeContext;

// This runs in a worker thread (safe to block)
void heavy_computation(void *context)
{
    ComputeContext *ctx = (ComputeContext *)context;
    
    // Simulate CPU-intensive work
    int sum = 0;
    for (int i = 0; i < 1000000000; i++)
    {
        sum += i;
    }
    
    ctx->result = sum;
}

// This runs on the main thread when heavy_computation is done
void computation_complete(void *context)
{
    ComputeContext *ctx = (ComputeContext *)context;
    
    char *response = arena_sprintf(ctx->res->arena, 
                                   "Computation result: %d", 
                                   ctx->result);
    
    send_text(ctx->res, 200, response);
}

// Route handler (runs on main thread)
void compute_handler(Req *req, Res *res)
{
    // Create context (arena-allocated)
    ComputeContext *ctx = arena_alloc(res->arena, sizeof(ComputeContext));
    ctx->res = res;
    ctx->result = 0;
    
    // Spawn the work
    spawn(ctx, heavy_computation, computation_complete);
    
    // Handler returns immediately
    // Response is sent when computation_complete runs
}

int main(void)
{
    server_init();
    
    get("/compute", compute_handler);
    
    server_listen(3000);
    server_run();
    
    return 0;
}
```

### Advanced Example

```c
#include "ecewo.h"

typedef struct
{
    Res *res;
    int total;
    int completed;
    int results[3];
    bool has_error;
} ParallelContext;

static void parallel_work_1(void *context)
{
    ParallelContext *ctx = context;
    
    // Simulate CPU-intensive work
    // In real code: database query, file I/O, API call, etc.
    ctx->results[0] = 10;
}

static void parallel_work_2(void *context)
{
    ParallelContext *ctx = context;
    ctx->results[1] = 20;
}

static void parallel_work_3(void *context)
{
    ParallelContext *ctx = context;
    ctx->results[2] = 30;
}

static void parallel_done(void *context)
{
    ParallelContext *ctx = context;
    ctx->completed++;
    
    // If any spawn failed
    if (ctx->has_error && ctx->completed == 1)
    {
        send_text(ctx->res, 500, "Task spawn failed");
        return;
    }
    
    // All tasks completed successfully
    if (ctx->completed == ctx->total && !ctx->has_error)
    {
        int sum = ctx->results[0] + ctx->results[1] + ctx->results[2];
        char *response = arena_sprintf(ctx->res->arena, "{\"sum\":%d}", sum);
        send_json(ctx->res, 200, response);
    }
}

void parallel_handler(Req *req, Res *res)
{
    ParallelContext *ctx = arena_alloc(res->arena, sizeof(ParallelContext));
    ctx->res = res;
    ctx->total = 3;
    ctx->completed = 0;
    ctx->results[0] = 0;
    ctx->results[1] = 0;
    ctx->results[2] = 0;
    ctx->has_error = false;
    
    // Launch 3 parallel tasks
    if (spawn(ctx, parallel_work_1, parallel_done) != 0)
        ctx->has_error = true;
    if (spawn(ctx, parallel_work_2, parallel_done) != 0)
        ctx->has_error = true;
    if (spawn(ctx, parallel_work_3, parallel_done) != 0)
        ctx->has_error = true;
    
    // If all spawns failed
    if (ctx->has_error && ctx->completed == 0)
        send_text(res, 500, "Failed to spawn tasks");
}

// ===== ROUTE REGISTRATION =====

int main(void)
{
    server_init();
    
    get("/parallel", parallel_handler);
    
    server_listen(3000);
    server_run();
    
    return 0;
}
```

> [!IMPORTANT]
>
> Be careful for long-running tasks while waiting for the result to send a response, there might be timeout problem. Consider that `spawn()` is more suitable for fire-and-forget background tasks.

## Notes

> [!IMPORTANT]
>
> The `spawn()` function uses libuv's thread pool (default: 4 threads). All blocking operations share this pool, so tasks may wait if all threads are busy. Set `UV_THREADPOOL_SIZE` environment variable to increase the thread pool size if needed.

```c
// If you have many concurrent requests with spawn(),
// increase thread pool size before starting server:

int main(void)
{
    // Set thread pool size (default is 4)
    setenv("UV_THREADPOOL_SIZE", "16", 1);
    
    server_init();
    get("/task", task_handler);
    server_listen(3000);
    server_run();
    
    return 0;
}
```

> [!DANGER]
>
> Never send response in work function.

```c
// WRONG - work_fn runs in worker thread
void wrong_work(void *context)
{
    MyContext *ctx = (MyContext *)context;
    send_text(ctx->res, 200, "Done"); // BUG!
}

// CORRECT - send response in done_fn
void correct_done(void *context)
{
    MyContext *ctx = (MyContext *)context;
    send_text(ctx->res, 200, "Done"); // Runs on main thread
}
```
