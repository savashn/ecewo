# Workers

ecewo provides powerful asynchronous capabilities for handling blocking operations efficiently, thanks to [libuv](https://libuv.org/). This guide covers how to execute CPU-bound tasks without blocking the event loop.

## Table of Contents

1. [Overview](#overview)
2. [The spawn() Function](#the-spawn-function)
3. [Fire-and-forget](#fire-and-forget)
4. [Wait and Respond](#wait-and-respond)
5. [Notes](#notes)

## Overview

Blocking computations should not run on the main event loop as they would block all other requests. ecewo provides the `spawn()` function to handle blocking CPU-bound operations safely by executing them in libuv's thread pool.

## The spawn() Function

The `spawn()` function executes blocking work in a worker thread and runs a callback on the main thread when complete.

**Signature:**
```c
int spawn(void *context, spawn_handler_t work_fn, spawn_handler_t done_fn);
```

**Parameters:**
- `context`: User context pointer (must contain arena for memory allocation)
- `work_fn`: Function to execute in worker thread (safe to block here)
- `done_fn`: Callback when work completes (runs on main thread, can be NULL)

**Returns:**
- `0` on success
- `-1` on failure

**Callback Signature:**
```c
typedef void (*spawn_handler_t)(void *context);
```

## Fire-and-forget

Send a response to client immediately and run a background task. You can run multiple parallel tasks.

### Basic Usage

```c
#include "ecewo.h"
#include <stdio.h>

typedef struct
{
    Arena *arena;
    int iterations;
} ComputeContext;

// This runs in a worker thread (safe to block)
void calculate_primes(void *context)
{
    ComputeContext *ctx = (ComputeContext *)context;
    
    printf("Computing primes up to %d...\n", ctx->iterations);
    
    int prime_count = 0;
    
    // CPU-intensive loop
    for (int num = 2; num <= ctx->iterations; num++)
    {
        int is_prime = 1;
        
        for (int i = 2; i * i <= num; i++)
        {
            if (num % i == 0)
            {
                is_prime = 0;
                break;
            }
        }
        
        if (is_prime)
            prime_count++;
    }
    
    printf("Found %d primes\n", prime_count);

    arena_return(ctx->arena);
}

void compute_handler(Req *req, Res *res)
{
    const char *iter_str = get_query(req, "iterations");
    int iterations = atoi(iter_str);
    
    // Create independent arena for background work
    Arena *bg_arena = arena_borrow();
    
    ComputeContext *ctx = arena_alloc(bg_arena, sizeof(ComputeContext));
    ctx->arena = bg_arena;
    ctx->iterations = iterations;
    
    // Offload to worker thread
    spawn(ctx, calculate_primes, NULL);
    
    // Handler returns immediately
    // Computation will work on background
    char *msg = arena_sprintf(req->arena, "Computation started");
    send_text(res, ACCEPTED, msg);
}

int main(void)
{
    server_init();
    
    get("/compute", compute_handler);
    
    server_listen(3000);
    server_run();
    
    return 0;
}
```

Go to `http://localhost:3000/compute?iterations=10000` address.

### Advanced Example

Here's a more complex example with multiple parallel tasks:

```c
#include "ecewo.h"

typedef struct
{
    Arena *arena;
    int total;
    int completed;
    int results[3];
} ParallelContext;

static void parallel_work_1(void *context)
{
    ParallelContext *ctx = (ParallelContext *)context;
    
    // CPU-intensive work
    int sum = 0;
    for (int i = 0; i < 100000000; i++)
    {
        sum += i % 100;
    }
    
    ctx->results[0] = sum % 1000;
}

static void parallel_work_2(void *context)
{
    ParallelContext *ctx = (ParallelContext *)context;
    
    int product = 1;
    for (int i = 1; i < 1000000; i++)
    {
        product = (product * i) % 10000;
    }
    
    ctx->results[1] = product % 1000;
}

static void parallel_work_3(void *context)
{
    ParallelContext *ctx = (ParallelContext *)context;
    
    int count = 0;
    for (int i = 2; i < 100000; i++)
    {
        int is_prime = 1;
        for (int j = 2; j * j <= i; j++)
        {
            if (i % j == 0)
            {
                is_prime = 0;
                break;
            }
        }
        if (is_prime)
            count++;
    }
    
    ctx->results[2] = count % 1000;
}

static void parallel_done(void *context)
{
    ParallelContext *ctx = (ParallelContext *)context;
    ctx->completed++;
    
    // All tasks completed
    if (ctx->completed == ctx->total)
    {
        int sum = ctx->results[0] + ctx->results[1] + ctx->results[2];

        printf("Background calculation completed. Sum: %d\n", sum);
        printf("  Task 1: %d\n", ctx->results[0]);
        printf("  Task 2: %d\n", ctx->results[1]);
        printf("  Task 3: %d\n", ctx->results[2]);
        
        arena_return(ctx->arena);
    }
}

void parallel_handler(Req *req, Res *res)
{
    Arena *bg_arena = arena_borrow();

    ParallelContext *ctx = arena_alloc(bg_arena, sizeof(ParallelContext));
    ctx->arena = bg_arena;
    ctx->total = 3;
    ctx->completed = 0;
    ctx->results[0] = 0;
    ctx->results[1] = 0;
    ctx->results[2] = 0;
    
    // Launch 3 parallel tasks
    spawn(ctx, parallel_work_1, parallel_done);
    spawn(ctx, parallel_work_2, parallel_done);
    spawn(ctx, parallel_work_3, parallel_done);

    // Send response immediately
    send_text(res, ACCEPTED, "Calculation started in background");
}
```

## Wait and Respond

Wait for the task and send a response to the client when it's done. You can run multiple parallel tasks.

### Basic Usage

```c
#include "ecewo.h"

typedef struct
{
    Res *res;
    int result;
} ComputeContext;

// This runs in a worker thread (safe to block)
void heavy_computation(void *context)
{
    ComputeContext *ctx = (ComputeContext *)context;
    
    // Simulate CPU-intensive work
    int sum = 0;
    for (int i = 0; i < 1000000000; i++)
    {
        sum += i;
    }
    
    ctx->result = sum;
}

// This runs on the main thread when heavy_computation is done
void computation_complete(void *context)
{
    ComputeContext *ctx = (ComputeContext *)context;
    
    char *response = arena_sprintf(ctx->res->arena, 
                                   "Computation result: %d", 
                                   ctx->result);
    
    send_text(ctx->res, 200, response);
}

// Route handler (runs on main thread)
void compute_handler(Req *req, Res *res)
{
    // Create context (arena-allocated)
    ComputeContext *ctx = arena_alloc(res->arena, sizeof(ComputeContext));
    ctx->res = res;
    ctx->result = 0;
    
    // Spawn the work
    spawn(ctx, heavy_computation, computation_complete);
    
    // Handler returns immediately
    // Response is sent when computation_complete runs
}

int main(void)
{
    server_init();
    
    get("/compute", compute_handler);
    
    server_listen(3000);
    server_run();
    
    return 0;
}
```

### Advanced Example

```c
#include "ecewo.h"

typedef struct
{
    Res *res;
    int total;
    int completed;
    int results[3];
    bool has_error;
} ParallelContext;

static void parallel_work_1(void *context)
{
    ParallelContext *ctx = context;
    
    // Simulate CPU-intensive work
    // In real code: database query, file I/O, API call, etc.
    ctx->results[0] = 10;
}

static void parallel_work_2(void *context)
{
    ParallelContext *ctx = context;
    ctx->results[1] = 20;
}

static void parallel_work_3(void *context)
{
    ParallelContext *ctx = context;
    ctx->results[2] = 30;
}

static void parallel_done(void *context)
{
    ParallelContext *ctx = context;
    ctx->completed++;
    
    // If any spawn failed
    if (ctx->has_error && ctx->completed == 1)
    {
        send_text(ctx->res, 500, "Task spawn failed");
        return;
    }
    
    // All tasks completed successfully
    if (ctx->completed == ctx->total && !ctx->has_error)
    {
        int sum = ctx->results[0] + ctx->results[1] + ctx->results[2];
        char *response = arena_sprintf(ctx->res->arena, "{\"sum\":%d}", sum);
        send_json(ctx->res, 200, response);
    }
}

void parallel_handler(Req *req, Res *res)
{
    ParallelContext *ctx = arena_alloc(res->arena, sizeof(ParallelContext));
    ctx->res = res;
    ctx->total = 3;
    ctx->completed = 0;
    ctx->results[0] = 0;
    ctx->results[1] = 0;
    ctx->results[2] = 0;
    ctx->has_error = false;
    
    // Launch 3 parallel tasks
    if (spawn(ctx, parallel_work_1, parallel_done) != 0)
        ctx->has_error = true;
    if (spawn(ctx, parallel_work_2, parallel_done) != 0)
        ctx->has_error = true;
    if (spawn(ctx, parallel_work_3, parallel_done) != 0)
        ctx->has_error = true;
    
    // If all spawns failed
    if (ctx->has_error && ctx->completed == 0)
        send_text(res, 500, "Failed to spawn tasks");
}

// ===== ROUTE REGISTRATION =====

int main(void)
{
    server_init();
    
    get("/parallel", parallel_handler);
    
    server_listen(3000);
    server_run();
    
    return 0;
}
```

> [!IMPORTANT]
>
> Be careful for long-running tasks while waiting for the result to send a response, there might be timeout problem. Consider that `spawn()` is more suitable for fire-and-forget background tasks.

## Notes

> [!IMPORTANT]
>
> The `spawn()` function uses libuv's thread pool (default: 4 threads). All blocking operations share this pool, so tasks may wait if all threads are busy. Set `UV_THREADPOOL_SIZE` environment variable to increase the thread pool size if needed.

```c
// If you have many concurrent requests with spawn(),
// increase thread pool size before starting server:

int main(void)
{
    // Set thread pool size (default is 4)
    setenv("UV_THREADPOOL_SIZE", "16", 1);
    
    server_init();
    get("/task", task_handler);
    server_listen(3000);
    server_run();
    
    return 0;
}
```

> [!DANGER]
>
> Never send response in work function.

```c
// WRONG - work_fn runs in worker thread
void wrong_work(void *context)
{
    MyContext *ctx = (MyContext *)context;
    send_text(ctx->res, 200, "Done"); // BUG!
}

// CORRECT - send response in done_fn
void correct_done(void *context)
{
    MyContext *ctx = (MyContext *)context;
    send_text(ctx->res, 200, "Done"); // Runs on main thread
}
```
